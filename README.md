# ML Optimization for Ad Bidding - Project Structure

## Overview

This project implements a machine learning pipeline for optimizing keyword bids in Google Ads. It includes data preprocessing, model training, and bid optimization using linear programming.

## Directory Structure

```
project/
├── data/                           # Processed data (generated by pipeline)
│   ├── ad_opt_data_tfidf.csv      # Full dataset with embeddings
│   ├── train_tfidf.csv            # Training set
│   └── test_tfidf.csv             # Test set
│
├── models/                         # Trained models (generated)
│   ├── lr_conversion.json         # Linear regression (conversion)
│   ├── lr_clicks.json             # Linear regression (clicks)
│   ├── oct_conversion.json        # Optimal trees (conversion)
│   ├── oct_clicks.json            # Optimal trees (clicks)
│   ├── rf_conversion.json         # Random forest (conversion)
│   ├── rf_clicks.json             # Random forest (clicks)
│   ├── xgb_conversion.json        # XGBoost (conversion)
│   └── xgb_clicks.json            # XGBoost (clicks)
│
├── notebooks/                      # Jupyter notebooks (reference/development)
│   ├── tidy_get_data.ipynb        # Data exploration & preprocessing
│   ├── tidy_get_data_tfidf.ipynb  # TF-IDF embedding generation
│   ├── prediction_modeling.ipynb  # Model training (Julia)
│   ├── bid_optimization.ipynb     # Bid optimization (Julia)
│   └── train_model.ipynb          # Additional model training
│
├── scripts/                        # Python production scripts
│   ├── tidy_get_data.py           # Data preparation pipeline (main entry)
│   ├── prediction_modeling.py     # Model training (requires IAI library)
│   ├── bid_optimization.py        # Bid optimization (requires Gurobi)
│   └── README.md                  # Scripts documentation
│
├── utils/                          # Reusable utility modules
│   ├── data_cleaning.py           # Currency & percentage parsing
│   ├── date_features.py           # Temporal feature extraction
│   ├── embeddings.py              # TF-IDF & BERT embeddings
│   ├── data_pipeline.py           # High-level pipeline functions
│   ├── __init__.py                # Central export point
│   └── README.md                  # Utils documentation
│
├── helpers.py                      # Backward-compatible re-exports (deprecated)
├── README.md                       # This file
└── requirements.txt                # Python dependencies
```

## Quick Start

### 1. Setup

```bash
# Install dependencies
pip install -r requirements.txt

# Optional: For bid optimization (requires Gurobi license)
pip install gurobipy

# Optional: For model training with IAI
pip install iai
```

### 2. Data Preparation

```bash
# Generate TF-IDF embeddings and prepare datasets
python scripts/tidy_get_data.py --embedding-method tfidf

# Or use BERT embeddings (slower, but more semantic)
python scripts/tidy_get_data.py --embedding-method bert
```

This script:
- Loads and combines 2024 and 2025 keyword data
- Cleans currency, percentages, and text
- Extracts temporal features (holidays, weekends, etc.)
- Merges with Google Keyword Planner data
- Generates keyword embeddings (TF-IDF or BERT)
- Creates train/test splits (75/25)
- Saves processed datasets to `data/` directory

**Output files:**
- `data/ad_opt_data_tfidf.csv` - Full dataset
- `data/train_tfidf.csv` - Training set (~53k rows)
- `data/test_tfidf.csv` - Test set (~18k rows)

### 3. Train Prediction Models

```bash
# Train models to predict conversion value
python scripts/prediction_modeling.py --target conversion

# Or predict clicks
python scripts/prediction_modeling.py --target clicks
```

Trains and compares:
- Linear Regression (LR) with feature selection
- Optimal Cart Trees (OCT)
- Random Forests (RF)
- XGBoost (XGB)

**Requirements:** IAI library (interpretable.ai)

**Output:** Models saved to `models/` directory

### 4. Optimize Bids

```bash
python scripts/bid_optimization.py \
  --budget 68096.51 \
  --max-bid 100 \
  --max-active 14229 \
  --output optimized_bids.csv
```

Uses Gurobi linear programming to maximize profit given:
- Budget constraint
- Maximum individual bid
- Maximum number of active keywords

**Requirements:** Gurobi solver (commercial license required)

**Output:** `optimized_bids.csv` with recommended bids

## Modules

### `utils/data_cleaning.py`
Utilities for parsing and normalizing data:
- `clean_currency()` - Parse currency strings
- `convert_percent_to_float()` - Parse percentage values

### `utils/date_features.py`
Temporal feature extraction:
- `_is_holiday()` - Detect public holidays
- `calculate_days_to_next()` - Days until next event
- `_region_to_country_code()` - Map regions to country codes

### `utils/embeddings.py`
Keyword embedding generation:
- `get_tfidf_embeddings()` - TF-IDF with TruncatedSVD (fast, interpretable)
- `get_bert_embeddings_pipeline()` - BERT with TruncatedSVD (semantic, accurate)
- `get_bert_embedding()` - Raw BERT embeddings (low-level)

### `utils/data_pipeline.py`
High-level pipeline functions (called by `scripts/tidy_get_data.py`):
- `load_and_combine_keyword_data()`
- `format_keyword_data()`
- `extract_date_features()`
- `merge_with_ads_data()`
- `add_embeddings()`
- `prepare_train_test_split()`
- `save_outputs()`

## Features

### Input Data
- Google Ads performance data (2024-2025)
- Google Keyword Planner data (search volume, competition, bid ranges)

### Engineered Features
**Temporal:**
- Day of week
- Weekend indicator
- Month
- Public holiday indicator
- Days to next course start

**Text/Semantic:**
- TF-IDF embeddings (50 dimensions)
- Or BERT embeddings (50 dimensions after SVD)

**Bid Features:**
- Average CPC
- Average bid (low + high range / 2)

**Categorical:**
- Match type (broad, exact, phrase)
- Region (USA, Region A, B, C)

### Target Variables
- **Conversion Value:** Revenue generated by conversion
- **Clicks:** Number of ad clicks

## Model Performance

Example results (MSE on test set):
```
Conversion Value Prediction:
  Linear Regression:  ~2500
  Optimal Trees:      ~2200
  Random Forest:      ~1800
  XGBoost:            ~1600

Click Prediction:
  Linear Regression:  ~15
  Optimal Trees:      ~12
  Random Forest:      ~8
  XGBoost:            ~6
```

## Optimization

The bid optimization formulates the problem as:

```
maximize:   sum(predicted_conversion - predicted_clicks * bid)
subject to:
  sum(bid) <= budget_limit
  bid[i] <= max_bid * active[i]
  sum(active) <= max_active_keywords
  bid >= 0, active ∈ {0, 1}
```

Where:
- `bid[i]` = CPC bid for keyword i
- `active[i]` = binary variable indicating if keyword is active
- Predictions come from trained models

## Dependencies

**Required:**
```
pandas>=1.3.0
numpy>=1.20.0
scikit-learn>=1.0.0
```

**Optional:**
```
# For BERT embeddings
sentence-transformers>=2.2.0

# For model training
iai>=3.0.0  # InterpretableAI (commercial)

# For bid optimization
gurobipy>=10.0  # Gurobi solver (commercial license required)

# For notebooks
jupyter>=1.0.0
matplotlib>=3.3.0
seaborn>=0.11.0
altair>=4.1.0
```

## Performance Notes

- **Data preparation:** ~30-60 seconds (TF-IDF), ~2-3 minutes (BERT with GPU)
- **Model training:** ~1-2 minutes per model (5-fold CV)
- **Bid optimization:** ~30 seconds to 2 minutes (depending on Gurobi settings)

## Troubleshooting

### Issue: `ModuleNotFoundError: No module named 'utils'`
**Solution:** Ensure you're running scripts from the project root directory:
```bash
cd /path/to/mlopt-final
python scripts/tidy_get_data.py
```

### Issue: `ImportError: No module named 'iai'`
**Solution:** Install IAI:
```bash
pip install iai
# Note: Requires a valid InterpretableAI license
```

### Issue: `ImportError: No module named 'gurobipy'`
**Solution:** Install Gurobi:
```bash
pip install gurobipy
# Note: Requires a valid Gurobi license
```

### Issue: IAI/Gurobi license errors
**Solution:** Obtain and configure licenses:
- IAI: https://www.interpretable.ai/
- Gurobi: https://www.gurobi.com/

## Workflow

Typical workflow:

```bash
# 1. Prepare data
python scripts/tidy_get_data.py --embedding-method tfidf

# 2. Train models (requires IAI)
python scripts/prediction_modeling.py --target conversion
python scripts/prediction_modeling.py --target clicks

# 3. Optimize bids (requires Gurobi)
python scripts/bid_optimization.py --budget 68096.51

# 4. Review results
head -20 optimized_bids.csv
```

## Further Development

### Potential Improvements
1. **Hyperparameter tuning** - Expand grid search ranges
2. **Ensemble methods** - Combine multiple models
3. **Stochastic optimization** - Account for uncertainty in predictions
4. **Multi-period optimization** - Dynamic bidding over time
5. **A/B testing framework** - Validate recommendations

### Adding New Features
1. Add feature extraction functions to `utils/date_features.py`
2. Update `utils/data_pipeline.py` to compute new features
3. Retrain models with new feature matrix

## References

- Google Ads API: https://developers.google.com/google-ads/api
- InterpretableAI (IAI): https://www.interpretable.ai/
- Gurobi Optimizer: https://www.gurobi.com/
- Scikit-learn: https://scikit-learn.org/
- Sentence-Transformers: https://www.sbert.net/

## License

[Your license here]

## Contact

[Your contact information]
